{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TICK_SIZE=26\n",
    "LABEL_SIZE=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set it as a personal checkpoint path, e.g. detault one should be \"./checkpoint/\"\n",
    "checkpoint_dir = \"./checkpoint/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#results for anti-correlated error\n",
    "task_up_1 = \"uu-ent-up1\"\n",
    "task_up_2 = \"uu-ent-up2\"\n",
    "task_down = \"uu-ent-down\"\n",
    "seed = 0\n",
    "para_to_vary_model_list = np.arange(10, 100.1, 10)\n",
    "num_para = len(para_to_vary_model_list)\n",
    "task_up_1_loss = np.zeros(num_para+ 1)\n",
    "task_up_2_loss = np.zeros(num_para + 1)\n",
    "repre = \"preds\"\n",
    "for i, para_to_vary_model in enumerate(para_to_vary_model_list):\n",
    "    checkpoint_path = f\"{checkpoint_dir}/checkpoint/svhn_resnet18_task_{task_up_1}_upstream_setting_None_para_to_vary_model_{para_to_vary_model}_seed_{seed}.pth\"\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    task_up_1_loss[i] = checkpoint[\"loss\"]\n",
    "    del checkpoint\n",
    "    \n",
    "for i, para_to_vary_model in enumerate(para_to_vary_model_list):\n",
    "    checkpoint_path = f\"{checkpoint_dir}/checkpoint/svhn_resnet18_task_{task_up_1}_upstream_setting_None_para_to_vary_model_{para_to_vary_model}_seed_{seed}.pth\"\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    task_up_2_loss[i] = checkpoint[\"loss\"]\n",
    "    del checkpoint\n",
    "\n",
    "task_down_loss_mat = np.zeros([num_para, num_para])\n",
    "for i, para_to_vary_model_1 in enumerate(para_to_vary_model_list):\n",
    "    for j, para_to_vary_model_2 in enumerate(para_to_vary_model_list):\n",
    "        checkpoint_path = f\"{checkpoint_dir}/checkpoint/svhn_linear_task_{task_down}_upstream_setting_{task_up_1}_{para_to_vary_model_1}_resnet18_{seed}_preds_last_{task_up_2}_{para_to_vary_model_2}_resnet18_{seed}_preds_last_para_to_vary_model_None_seed_{seed}.pth\"\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        task_down_loss_mat[i, j] += checkpoint[\"loss\"]\n",
    "        del checkpoint\n",
    "\n",
    "np.savez(\"results_for_figs/anti-correlated_error\", loss_up_1=task_up_1_loss, loss_up_2=task_up_2_loss, loss_down=task_down_loss_mat)\n",
    "    \n",
    "results = np.load(\"results_for_figs/anti-correlated_error.npz\")\n",
    "loss_up_1 = results[\"loss_up_1\"]\n",
    "loss_up_2 = results[\"loss_up_2\"]\n",
    "loss_down = results[\"loss_down\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10*0.9,9*0.9))\n",
    "hmap = ax.imshow(loss_down, cmap=\"YlOrRd\")\n",
    "cbar = plt.colorbar(hmap)\n",
    "cbar.set_label(\"Downstream test loss ($\\ell_w$)\", size=LABEL_SIZE, fontweight=\"bold\")\n",
    "for l in cbar.ax.yaxis.get_ticklabels():\n",
    "    l.set_fontsize(TICK_SIZE)\n",
    "\n",
    "ax.set_ylabel(\"Upstream test loss ($\\ell_u$)\", fontsize=LABEL_SIZE, fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Upstream test loss ($\\ell_v$)\", fontsize=LABEL_SIZE, fontweight=\"bold\")\n",
    "\n",
    "# #dense ticks\n",
    "# ax.set_yticks(np.arange(len(loss_up_1)))\n",
    "# ax.set_yticklabels(['%.2f' % a for a in loss_up_1], rotation=0, fontsize=TICK_SIZE)\n",
    "# ax.set_xticks(np.arange(len(loss_up_2)))\n",
    "# ax.set_xticklabels(['%.2f' % a for a in loss_up_2], rotation=45, fontsize=TICK_SIZE)\n",
    "\n",
    "#sparse ticks\n",
    "ax.set_yticks(np.arange( int((len(loss_up_1)-1)) / 2) * 2)\n",
    "ax.set_yticklabels(['%.2f' % a for a in loss_up_1[np.arange(0, len(loss_up_1)-1, 2)]], rotation=0, fontsize=TICK_SIZE)\n",
    "ax.set_xticks(np.arange( int((len(loss_up_2)-1)) / 2) * 2)\n",
    "ax.set_xticklabels(['%.2f' % a for a in loss_up_2[np.arange(0, len(loss_up_2)-1, 2)]], rotation=45, fontsize=TICK_SIZE)\n",
    "ax.invert_yaxis()\n",
    "#plt.show()\n",
    "plt.savefig('results_for_figs/anti-correlated_error.pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#results for data-distribution mismatch\n",
    "task_up = \"dd-mis-up\"\n",
    "task_down = \"dd-mis-down\"\n",
    "repre = \"feat\"\n",
    "model_specify = \"last\"\n",
    "para_to_vary_model_list = np.arange(10, 100.1, 10)\n",
    "num_para = len(para_to_vary_model_list)\n",
    "num_seed = 1\n",
    "\n",
    "model = \"resnet18\"\n",
    "task_up_loss = np.zeros(num_para)\n",
    "task_down_loss = np.zeros(num_para)\n",
    "task_up_loss_std = np.zeros(num_para)\n",
    "task_down_loss_std = np.zeros(num_para)\n",
    "\n",
    "for i, para_to_vary_model in enumerate(para_to_vary_model_list):\n",
    "    para_to_vary_model = float(para_to_vary_model)\n",
    "    loss = np.zeros([num_seed])\n",
    "    for seed in range(num_seed):\n",
    "        checkpoint_path = f\"{checkpoint_dir}/checkpoint/svhn_{model}_task_{task_up}_upstream_setting_None_para_to_vary_model_{para_to_vary_model}_seed_{seed}.pth\"\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        loss[seed] = (checkpoint[\"knn_loss\"])\n",
    "        del checkpoint\n",
    "    task_up_loss[i] = loss.mean()\n",
    "    task_up_loss_std[i] = loss.std()\n",
    "\n",
    "\n",
    "for i, para_to_vary_model in enumerate(para_to_vary_model_list):\n",
    "    para_to_vary_model = float(para_to_vary_model)\n",
    "    loss = np.zeros([num_seed])\n",
    "    for seed in range(num_seed):\n",
    "        checkpoint_path = f\"{checkpoint_dir}/checkpoint/svhn_linear_task_{task_down}_upstream_setting_{task_up}_{para_to_vary_model}_{model}_{seed}_{repre}_{model_specify}_para_to_vary_model_None_seed_{seed}.pth\"\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        loss[seed] = checkpoint[\"loss\"]\n",
    "        del checkpoint\n",
    "    task_down_loss[i] = loss.mean()\n",
    "    task_down_loss_std[i] = loss.std()\n",
    "    \n",
    "np.savez(\"results_for_figs/data-distribution_mismatch\", loss_up_mean=task_up_loss, loss_up_std=task_up_loss_std, loss_down_mean=task_down_loss, loss_down_std=task_down_loss_std)\n",
    "\n",
    "results = np.load(\"results_for_figs/data-distribution_mismatch.npz\")\n",
    "loss_up_mean = results[\"loss_up_mean\"]\n",
    "loss_up_std = results[\"loss_up_std\"]\n",
    "loss_down_mean = results[\"loss_down_mean\"]\n",
    "loss_down_std = results[\"loss_down_std\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "caps_set = [None, None]\n",
    "(_, caps_set[0], _) = ax.errorbar(np.arange(10, 100.1, 10), loss_up_mean, yerr=loss_up_std, marker=\".\", label=\"Upstream model\", capsize=8, lw=4, color=\"C0\")\n",
    "ax.set_xlabel(\"Training subset (p%)\", fontsize=LABEL_SIZE, fontweight=\"bold\")\n",
    "ax.set_ylabel(\"Upstream test loss\", fontsize=LABEL_SIZE, fontweight=\"bold\")\n",
    "ax.set_xticks(np.arange(10, 100.1, 10).astype(np.int))\n",
    "ax.set_xticklabels(np.arange(10, 100.1, 10).astype(np.int), fontsize=TICK_SIZE)#, rotation=45\n",
    "ax.tick_params(axis='y', labelsize=TICK_SIZE)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "(_, caps_set[1], _) = ax2.errorbar(np.arange(10, 100.1, 10), loss_down_mean, yerr=loss_down_std, marker=\".\", label=\"downstream\", capsize=8, lw=4, color=\"C1\")\n",
    "ax2.set_ylabel(\"Downstream test loss\", fontsize=LABEL_SIZE, fontweight=\"bold\")\n",
    "ax2.tick_params(axis='y', labelsize=TICK_SIZE)\n",
    "ax2.locator_params(axis='y', nbins=5)\n",
    "\n",
    "#caps size for error bar\n",
    "for caps in caps_set:\n",
    "    for cap in caps:\n",
    "        cap.set_markeredgewidth(2)\n",
    "\n",
    "plt.xticks(fontsize=TICK_SIZE)\n",
    "plt.yticks(fontsize=TICK_SIZE)\n",
    "\n",
    "ax.set_axisbelow(True)\n",
    "ax.grid()\n",
    "ax.spines['right'].set_linewidth(3)\n",
    "ax.spines['left'].set_linewidth(3)\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['bottom'].set_linewidth(3)\n",
    "\n",
    "plt.savefig(\"results_for_figs/data-distribution_mismatch.pdf\", bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#legend\n",
    "figsize = (5, 1)\n",
    "fig_leg = plt.figure(figsize=figsize)\n",
    "legend_properties = {'weight': 'bold', 'size': LABEL_SIZE}\n",
    "ax_leg = fig_leg.add_subplot(111)\n",
    "#merge two legend\n",
    "legend_handles_labels = (ax.get_legend_handles_labels()[0] + ax2.get_legend_handles_labels()[0], \n",
    "                         ax.get_legend_handles_labels()[1] + ax2.get_legend_handles_labels()[1])\n",
    "ax_leg.axis('off')\n",
    "fig_leg.savefig('results_for_figs/legend.pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#results for loss-function mismatch\n",
    "task_up = \"lf-mis-up\"\n",
    "task_down = \"lf-mis-down\"\n",
    "repre = \"logits\"\n",
    "model_specify = \"best\"\n",
    "para_to_vary_model_list = np.arange(0, 10, 1)\n",
    "num_para = len(para_to_vary_model_list)\n",
    "num_seed = 40\n",
    "\n",
    "model = \"resnet18\"\n",
    "task_up_loss = np.zeros(num_para)\n",
    "task_down_loss = np.zeros(num_para)\n",
    "task_up_loss_std = np.zeros(num_para)\n",
    "task_down_loss_std = np.zeros(num_para)\n",
    "\n",
    "for i, para_to_vary_model in enumerate(para_to_vary_model_list):\n",
    "    para_to_vary_model = float(para_to_vary_model)\n",
    "    loss = np.zeros([num_seed])\n",
    "    for seed in range(num_seed):\n",
    "        checkpoint_path = f\"{checkpoint_dir}/checkpoint/svhn_{model}_task_{task_up}_upstream_setting_None_para_to_vary_model_{para_to_vary_model}_seed_{seed}.pth\"\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        loss[seed] = (checkpoint[\"best_state\"][\"loss\"])\n",
    "        del checkpoint\n",
    "    task_up_loss[i] = loss.mean()\n",
    "    task_up_loss_std[i] = loss.std()\n",
    "\n",
    "\n",
    "for i, para_to_vary_model in enumerate(para_to_vary_model_list):\n",
    "    para_to_vary_model = float(para_to_vary_model)\n",
    "    loss = np.zeros([num_seed])\n",
    "    for seed in range(num_seed):\n",
    "        checkpoint_path = f\"{checkpoint_dir}/checkpoint/svhn_MLP-128_task_{task_down}_upstream_setting_{task_up}_{para_to_vary_model}_{model}_{seed}_{repre}_{model_specify}_para_to_vary_model_None_seed_{seed}.pth\"\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        loss[seed] = checkpoint[\"loss\"]\n",
    "        del checkpoint\n",
    "    task_down_loss[i] = loss.mean()\n",
    "    task_down_loss_std[i] = loss.std()\n",
    "\n",
    "np.savez(\"results_for_figs/loss-function_mismatch\", loss_up_mean=task_up_loss, loss_up_std=task_up_loss_std, loss_down_mean=task_down_loss, loss_down_std=task_down_loss_std)\n",
    "\n",
    "results = np.load(\"results_for_figs/loss-function_mismatch.npz\")\n",
    "loss_up_mean = results[\"loss_up_mean\"]\n",
    "loss_up_std = results[\"loss_up_std\"]\n",
    "loss_down_mean = results[\"loss_down_mean\"]\n",
    "loss_down_std = results[\"loss_down_std\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "caps_set = [None, None]\n",
    "(_, caps_set[0], _) = ax.errorbar(np.arange(10, 100.1, 10), loss_up_mean, yerr=loss_up_std, marker=\".\", label=\"upstream\", capsize=8, lw=4, color=\"C0\")\n",
    "ax.set_xlabel(\"Rate of noisy examples (r)\", fontsize=LABEL_SIZE, fontweight=\"bold\")\n",
    "ax.set_ylabel(\"Upstream test loss\", fontsize=LABEL_SIZE, fontweight=\"bold\")\n",
    "ax.set_xticks(np.arange(10, 100.1, 10).astype(np.int))\n",
    "ax.set_xticklabels(para_to_vary_model_list.astype(np.int), fontsize=TICK_SIZE)#, rotation=45\n",
    "ax.tick_params(axis='y', labelsize=TICK_SIZE)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "(_, caps_set[1], _) = ax2.errorbar(np.arange(10, 100.1, 10), loss_down_mean, yerr=loss_down_std, marker=\".\", label=\"downstream\", capsize=8, lw=4, color=\"C1\")\n",
    "ax2.set_ylabel(\"Downstream test loss\", fontsize=LABEL_SIZE, fontweight=\"bold\")\n",
    "ax2.tick_params(axis='y', labelsize=TICK_SIZE)\n",
    "ax2.locator_params(axis='y', nbins=5)\n",
    "\n",
    "#caps size for error bar\n",
    "for caps in caps_set:\n",
    "    for cap in caps:\n",
    "        cap.set_markeredgewidth(2)\n",
    "\n",
    "plt.xticks(fontsize=TICK_SIZE)\n",
    "plt.yticks(fontsize=TICK_SIZE)\n",
    "\n",
    "ax.set_axisbelow(True)\n",
    "ax.grid()\n",
    "\n",
    "ax.spines['right'].set_linewidth(3)\n",
    "ax.spines['left'].set_linewidth(3)\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['bottom'].set_linewidth(3)\n",
    "\n",
    "#plt.show()\n",
    "plt.savefig('results_for_figs/loss-function_mismatch.pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#results for hypothesis-space mismatch\n",
    "num_seed = 1\n",
    "task_up = \"hs-mis-up\"\n",
    "task_down = \"hs-mis-down\"\n",
    "repre = \"feat\"\n",
    "model_specify = \"last\"\n",
    "\n",
    "model_set = [\"convnet\", \"convnet-512\", \"convnet-512-256\", \"convnet-512-256-128\", \"convnet-512-256-128-64\"]\n",
    "depth_set = [\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
    "\n",
    "num_model = len(model_set)\n",
    "task_up_loss = np.zeros(num_model)\n",
    "task_down_loss = np.zeros(num_model)\n",
    "task_up_loss_std = np.zeros(num_model)\n",
    "task_down_loss_std = np.zeros(num_model)\n",
    "\n",
    "for i, model in enumerate(model_set):\n",
    "    loss = np.zeros([num_seed])\n",
    "    for seed in range(num_seed):\n",
    "        checkpoint_path = f\"{checkpoint_dir}/checkpoint/svhn_{model}_task_{task_up}_upstream_setting_None_para_to_vary_model_None_seed_{seed}.pth\"\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        loss[seed] = checkpoint[\"knn_loss\"]\n",
    "        del checkpoint\n",
    "    task_up_loss[i] = loss.mean()\n",
    "    task_up_loss_std[i] = loss.std()\n",
    "\n",
    "for i, model in enumerate(model_set):\n",
    "    loss = np.zeros([num_seed])\n",
    "    for seed in range(num_seed):\n",
    "        checkpoint_path = f\"{checkpoint_dir}/checkpoint/svhn_linear_task_{task_down}_upstream_setting_{task_up}_None_{model}_{seed}_{repre}_{model_specify}_para_to_vary_model_None_seed_{seed}.pth\"\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        loss[seed] = checkpoint[\"loss\"]\n",
    "        del checkpoint\n",
    "    task_down_loss[i] = loss.mean()\n",
    "    task_down_loss_std[i] = loss.std()\n",
    "\n",
    "np.savez(\"results_for_figs/hypothesis-space_mismatch\", loss_up_mean=task_up_loss, loss_up_std=task_up_loss_std, loss_down_mean=task_down_loss, loss_down_std=task_down_loss_std)\n",
    "\n",
    "results = np.load(\"results_for_figs/hypothesis-space_mismatch.npz\")\n",
    "loss_up_mean = results[\"loss_up_mean\"]\n",
    "loss_up_std = results[\"loss_up_std\"]\n",
    "loss_down_mean = results[\"loss_down_mean\"]\n",
    "loss_down_std = results[\"loss_down_std\"]\n",
    "\n",
    "depth_set = [\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "caps_set = [None, None]\n",
    "(_, caps_set[0], _) = ax.errorbar(range(len(depth_set)), loss_up_mean, yerr=loss_up_std, marker=\".\", label=\"upstream\", capsize=8, lw=4, color=\"C0\")\n",
    "\n",
    "ax.set_xticks(range(len(depth_set)))\n",
    "ax.set_xticklabels(depth_set, fontsize=TICK_SIZE)#, rotation=45\n",
    "ax.set_ylabel(\"Upstream Test loss\", fontsize=LABEL_SIZE, fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Number of layers in MLP\", fontsize=LABEL_SIZE, fontweight=\"bold\")\n",
    "ax.tick_params(axis='y', labelsize=TICK_SIZE)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "(_, caps_set[1], _) = ax2.errorbar(range(len(depth_set)), loss_down_mean, yerr=loss_down_std, marker=\".\", label=\"downstream\", capsize=8, lw=4, color=\"C1\")\n",
    "\n",
    "for caps in caps_set:\n",
    "    for cap in caps:\n",
    "        cap.set_markeredgewidth(2)\n",
    "\n",
    "ax2.set_ylabel(\"Downstream test loss\", fontsize=LABEL_SIZE, fontweight=\"bold\")\n",
    "ax2.tick_params(axis='y', labelsize=TICK_SIZE)\n",
    "ax2.locator_params(axis='y', nbins=5)\n",
    "\n",
    "plt.xticks(fontsize=TICK_SIZE)\n",
    "plt.yticks(fontsize=TICK_SIZE)\n",
    "\n",
    "ax.set_axisbelow(True)\n",
    "ax.grid()\n",
    "ax.spines['right'].set_linewidth(3)\n",
    "ax.spines['left'].set_linewidth(3)\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['bottom'].set_linewidth(3)\n",
    "\n",
    "#plt.show()\n",
    "plt.savefig('hypothesis-space_mismatch.pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model_interact",
   "language": "python",
   "name": "model_interact"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
